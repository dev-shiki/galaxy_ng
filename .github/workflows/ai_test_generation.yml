name: AI-Powered Test Generation

on:
  workflow_dispatch:
    inputs:
      limit:
        description: 'Maximum number of modules to generate tests for'
        required: false
        default: '5'
        type: number
      model:
        description: 'SambaNova model to use'
        required: false
        default: 'Meta-Llama-3.1-8B-Instruct'
        type: string
      create_pr:
        description: 'Create PR with generated tests'
        required: false
        default: true
        type: boolean
      ai_correction:
        description: 'Use AI-assisted error correction'
        required: false
        default: true
        type: boolean

jobs:
  analyze-coverage:
    name: Analyze Coverage and Generate Tests
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for better context
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"
      
      - name: Install system dependencies
        run: |
          sudo apt update
          sudo apt install -y libsasl2-dev libldap2-dev libssl-dev gettext
      
      - name: Install dependencies
        run: |
          # Install core requirements
          python -m pip install --upgrade pip wheel setuptools
          pip install numpy
          pip install tox pytest pytest-django pytest-cov

          # Install required packages for the scripts
          pip install requests

          # Install the package itself in development mode
          pip install -e .
      
      - name: Create test infrastructure
        run: |
          # Create a mock pulp_smash config to avoid errors
          mkdir -p ~/.config/pulp_smash
          cat << EOF > ~/.config/pulp_smash/settings.json
          {
              "pulp": {
                  "auth": ["admin", "admin"],
                  "version": "3.0",
                  "selinux enabled": false
              },
              "hosts": [
                  {
                      "hostname": "localhost",
                      "roles": {
                          "api": {"port": 24817, "scheme": "http", "service": "nginx"},
                          "content": {"port": 24816, "scheme": "http", "service": "pulp_content_app"},
                          "pulp resource manager": {},
                          "pulp workers": {},
                          "redis": {},
                          "shell": {"transport": "local"},
                          "squid": {}
                      }
                  }
              ]
          }
          EOF

          # Create pytest.ini to configure pytest
          cat > pytest.ini << EOF
          [pytest]
          testpaths = galaxy_ng
          python_files = test_*.py
          python_classes = Test*
          python_functions = test_*
          addopts = -p no:pulp_ansible -p no:pulpcore -p no:pulp_smash
          EOF

          # Create directory structure for generated tests
          mkdir -p galaxy_ng/tests/unit/ai_generated/
          touch galaxy_ng/tests/unit/ai_generated/__init__.py
          touch galaxy_ng/tests/__init__.py
          touch galaxy_ng/tests/unit/__init__.py
      
      - name: Run original tests
        run: |
          # Run tests with tox as it was working before
          tox --colored yes -e py311 || true
          
          # Make a backup of the original coverage.xml
          if [ -f coverage.xml ]; then
            cp coverage.xml original_coverage.xml
          else
            echo "<?xml version='1.0' encoding='UTF-8'?><coverage></coverage>" > original_coverage.xml
          fi
      
      - name: Analyze coverage for test candidates
        run: |
          python .github/scripts/coverage_analyzer.py original_coverage.xml test_candidates.json
      
      - name: Set up SambaNova API Key
        run: |
          echo "SAMBANOVA_API_KEY=${{ secrets.SAMBANOVA_API_KEY }}" >> $GITHUB_ENV
      
      - name: Generate tests with AI
        run: |
          mkdir -p generated_tests
          python .github/scripts/ai_test_generator.py \
            --candidates test_candidates.json \
            --limit ${{ github.event.inputs.limit }} \
            --model ${{ github.event.inputs.model }} \
            --output-dir generated_tests
      
      - name: Run Test Fixes with AI-assisted correction
        if: ${{ github.event.inputs.ai_correction == 'true' }}
        run: |
          # Only run the test fixer if there are generated tests
          if [ -d "galaxy_ng/tests/unit/ai_generated" ] && [ "$(ls -A galaxy_ng/tests/unit/ai_generated)" ]; then
            echo "Fixing generated tests with AI assistance..."
            python .github/scripts/fix_test_files.py \
              --path galaxy_ng/tests/unit/ai_generated \
              --api-key "$SAMBANOVA_API_KEY" \
              --model "${{ github.event.inputs.model }}"
          else
            echo "No tests to fix."
          fi
        env:
          SAMBANOVA_API_KEY: ${{ secrets.SAMBANOVA_API_KEY }}
      
      - name: Run Test Fixes without AI assistance
        if: ${{ github.event.inputs.ai_correction != 'true' }}
        run: |
          # Only run the test fixer if there are generated tests
          if [ -d "galaxy_ng/tests/unit/ai_generated" ] && [ "$(ls -A galaxy_ng/tests/unit/ai_generated)" ]; then
            echo "Fixing generated tests with standard fixes..."
            python .github/scripts/fix_test_files.py --path galaxy_ng/tests/unit/ai_generated
          else
            echo "No tests to fix."
          fi
      
      - name: Validate Fixed Tests
        run: |
          # Create a simple script to check test files
          cat > check_tests.py << 'EOF'
          import os
          import sys
          import ast
          import re

          def check_file(filepath):
              print(f"Checking {filepath}...")
              try:
                  with open(filepath, 'r') as f:
                      content = f.read()
                  
                  # Check for proper Django setup
                  if "django.setup()" not in content:
                      print(f"WARNING: Django setup missing in {filepath}")
                  
                  # Check for factory imports
                  if re.search(r'from galaxy_ng\.[^\s]+\s+import\s+factories', content):
                      print(f"WARNING: Direct factory import in {filepath}")
                  
                  # Validate syntax
                  try:
                      ast.parse(content)
                      print(f"✅ {filepath} is syntactically valid")
                      return True
                  except SyntaxError as e:
                      print(f"❌ {filepath} has syntax error: {e}")
                      return False
              except Exception as e:
                  print(f"Error checking {filepath}: {e}")
                  return False

          # Check all test files in the directory
          test_dir = "galaxy_ng/tests/unit/ai_generated"
          valid_count = 0
          error_count = 0

          if os.path.exists(test_dir):
              for file in os.listdir(test_dir):
                  if file.endswith(".py") and file != "__init__.py":
                      file_path = os.path.join(test_dir, file)
                      if check_file(file_path):
                          valid_count += 1
                      else:
                          error_count += 1
              
              print(f"\nValidation results: {valid_count} valid, {error_count} with errors")
              sys.exit(1 if error_count > 0 else 0)
          else:
              print(f"Test directory {test_dir} not found")
              sys.exit(1)
          EOF

          # Run the checking script
          python check_tests.py || echo "Some tests need additional fixes"
      
      - name: Try running generated tests
        run: |
          # Create a proper conftest.py in the ai_generated directory
          cat > galaxy_ng/tests/unit/ai_generated/conftest.py << 'EOF'
          import os
          import sys
          import pytest

          # Setup Django environment
          os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'galaxy_ng.settings')

          # Add project root to path
          project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), "../../../.."))
          if project_root not in sys.path:
              sys.path.insert(0, project_root)

          # Import Django and setup
          import django
          django.setup()

          # Add fixtures here if needed
          @pytest.fixture
          def mock_request():
              from unittest.mock import MagicMock
              return MagicMock()
          EOF

          # Attempt to collect tests to verify they can be imported
          python -m pytest galaxy_ng/tests/unit/ai_generated/ \
            --collect-only \
            -p no:pulp_ansible \
            -p no:pulpcore \
            -p no:pulp_smash \
            -v || echo "Some tests can't be collected"
      
      - name: Upload generated tests artifact
        uses: actions/upload-artifact@v4
        with:
          name: ai-generated-tests
          path: galaxy_ng/tests/unit/ai_generated/
          retention-days: 7
      
      - name: Upload test candidates artifact
        uses: actions/upload-artifact@v4
        with:
          name: test-candidates
          path: test_candidates.json
          retention-days: 7
      
      - name: Upload coverage artifact
        uses: actions/upload-artifact@v4
        with:
          name: coverage-data
          path: original_coverage.xml
          retention-days: 7
      
      - name: Create combined PR
        if: ${{ github.event.inputs.create_pr == 'true' }}
        uses: peter-evans/create-pull-request@v5
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          commit-message: "Add AI-Generated tests to improve coverage"
          title: "AI-Generated Tests"
          body: |
            This PR contains AI-generated tests to improve code coverage.
            
            The tests have been placed in the `galaxy_ng/tests/unit/ai_generated/` directory and have been preprocessed 
            to fix common issues like:
            - Non-existent factory imports
            - Hyphenated module names
            - Unclosed parentheses
            - Missing Django environment setup
            - Special module handling for __init__.py files
            
            Generated using:
            - Model: ${{ github.event.inputs.model }}
            - Modules analyzed: ${{ github.event.inputs.limit }}
            - AI-assisted correction: ${{ github.event.inputs.ai_correction }}
            
            No-Issue
          branch: ai-generated-tests-${{ github.run_id }}
          base: ${{ github.ref_name }}
          labels: |
            ai-generated
            testing
            automated-pr